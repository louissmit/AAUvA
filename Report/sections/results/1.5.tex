In this assignment, a new internal state representation is implemented. Instead of using the old state representation wherine the absolute positions of both the predator and the prey are stored, this new representation only holds the distance between the predator and the prey, expressed as a tuple of the horizontal distance and the vertical distance. This representation is possible without violating the Markov property due to the toroidal nature of the board. \\

The new state representation has important consequences for the size of the state space. In the old representation, both the predator and the prey could be in one of $11 \times 11$ locations, amounting for a total of $11 \times 11 \times 11 \times 11 = 14641$ states. In the new representation, the distance between predator and prey can be represented as one of $11 \times 11 = 121$ states, reducing the state space by a factor $121$.

As a result, the scripts for policy evaluation and value iteration written earlier have been sped up. In the old representation, policy evaluation took 2.997 seconds, which has been improved to 1.968 seconds. A larger improvement was found for value iteration, which improved from 1.361, 2.424, 2.822 and 3.058 seconds to 0.035, 0.014, 0.039 and 0.017 seconds respectively for different values of the discount factor.

The best results in terms of time and number of iterations are observed for gamma equals 0.1. Increasing gamma factor causes increasing both factors. Changing data representation to distance based not only decrease computing time but also number of iterations. It can be observed that value iteration script performs approximately 100 times faster in comparison to the classic representation where positions of prey and predators are stored.